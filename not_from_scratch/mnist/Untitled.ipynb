{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "balanced-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as pt\n",
    "from tensorflow.keras.datasets.mnist import load_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "consecutive-enhancement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test dataset: 10000\n",
      "Length of train dataset: 60000\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "n_train = len(x_train)\n",
    "n_test = len(x_test)\n",
    "\n",
    "print(f\"Length of test dataset: {n_test}\")\n",
    "print(f\"Length of train dataset: {n_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-vertical",
   "metadata": {},
   "source": [
    "### Lets take a look at one of these images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "regulation-reasoning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAANiElEQVR4nO3db6hc9Z3H8c/HP2VJ6oPEaAyp2m6xZKt07XINCytuRNTokyQPlAYsWVCvD+rSQltWs6wVRJFl2wr7oHqD4t3daik2wbAsa9JsQaVU7jW4mj9aXYkmIeYaAltLoF2T7z64R7mJM+fczDlnziTf9wuGmTnfOTNfx/vJOTPn/ObniBCAs985XTcAYDgIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwo6ebP+Z7f+y/b+237G9ruueUA9hx2fYPk/S85L+XdJiSeOS/s32VzptDLWYM+hwKttXSfqNpAui+AOxvU3SKxHxD502h4GxZcd8WdJVXTeBwRF29PKWpBlJ37d9vu2bJP21pAXdtoU62I1HT7a/JumfNbs1n5b0oaQ/RMSdnTaGgRF2zIvtX0uajIgnuu4Fg2E3Hj3Z/prtP7G9wPb3JC2T9HTHbaEGwo5+vinpkGY/u98g6caI+EO3LaEOduOBJNiyA0kQdiAJwg4kQdiBJM4b5ovZ5ttAoGUR4V7La23Zba+2/VYxBPK+Os8FoF0DH3qzfa6k30q6UdIBSVOS1kfEnpJ12LIDLWtjy75S0jsR8W5E/FHSzyStqfF8AFpUJ+zLJe2fc/9AsewktsdtT9uervFaAGpq/Qu6iJiQNCGxGw90qc6W/aCkS+fc/0KxDMAIqhP2KUlX2P6S7c9J+oakrc20BaBpA+/GR8THtu+V9IKkcyU9FRG7G+sMQKOGOuqNz+xA+1o5qQbAmYOwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kMTA87NLku19kj6SdFzSxxEx1kRTAJpXK+yF6yPiSAPPA6BF7MYDSdQNe0jaZvtV2+O9HmB73Pa07emarwWgBkfE4CvbyyPioO2LJW2X9LcR8WLJ4wd/MQDzEhHutbzWlj0iDhbXM5K2SFpZ5/kAtGfgsNteaPuCT25LuknSrqYaA9CsOt/GL5W0xfYnz/NMRPxnI12hMevWrSut33zzzbXWL/7/9/XII4/0rT322GOl66JZA4c9It6V9OcN9gKgRRx6A5Ig7EAShB1IgrADSRB2IIlaZ9Cd9otxBl0rpqam+tZWrFhRuu6CBQtK61V/H1WH3srWP++8JsZh4VStnEEH4MxB2IEkCDuQBGEHkiDsQBKEHUiCsANJcKBzBDz00EOl9Y0bN5bWjx071re2ZcuW0nVffvnl0nqVJ554orR+4sSJWs+P5rBlB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGM8+BFU/x/zcc8+V1vfs2VNav+222/rW3nzzzdJ16zp+/Hhp/eGHH+5be+CBB5puB2I8O5AeYQeSIOxAEoQdSIKwA0kQdiAJwg4kwXj2BoyNjZXWH3/88dL6/v37S+vXX399af3IkSOl9TZdeeWVpfWLL764b63qHI/Vq1eX1l944YXSOk5WuWW3/ZTtGdu75ixbbHu77beL60Xttgmgrvnsxj8t6dR/Yu+TtCMirpC0o7gPYIRVhj0iXpR09JTFayRNFrcnJa1tti0ATRv0M/vSiDhU3P5A0tJ+D7Q9Lml8wNcB0JDaX9BFRJQNcImICUkTUt6BMMAoGPTQ22HbyySpuJ5priUAbRg07FslbShub5D0fDPtAGhL5W687WclrZK0xPYBST+Q9Kikn9u+U9J7km5vs8lRd9ddd5XWL7zwwtJ62Xh0qdvj6FWqxstfd911fWtVvyk/OTlZWr/kkktK6zhZZdgjYn2f0g0N9wKgRZwuCyRB2IEkCDuQBGEHkiDsQBIMcZ2nskNI99xzT+m6VUNcq6ZVPlvZPX/x+FMXXXTRkDrJgS07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBcfZ5WrFiRd9a1VDNzMret6qfkh7mdOIZsGUHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQ4zj5PH374Yd/aOeecvf9mrlu3rrR+xx13lNbXrl3bt1Y1nv2ll14qreP0nL1/pQBOQtiBJAg7kARhB5Ig7EAShB1IgrADSXiYY4Ztn5UDlHfv3l1ar5qy+ZlnnimtV02LXMfdd99dWi8bjy5JCxYsKK2X/X1VHWe/5ZZbSuvbtm0rrWcVET3f2Motu+2nbM/Y3jVn2YO2D9p+rbjc2mSzAJo3n934pyWt7rH8xxFxdXH5j2bbAtC0yrBHxIuSjg6hFwAtqvMF3b22Xy928xf1e5DtcdvTtqdrvBaAmgYN+08kfVnS1ZIOSfphvwdGxEREjEXE2ICvBaABA4U9Ig5HxPGIOCFpk6SVzbYFoGkDhd32sjl310na1e+xAEZD5Xh2289KWiVpie0Dkn4gaZXtqyWFpH2SyicoP8utWrWqtH7//feX1qvGhFedC1E2j/nevXtL1z127FhpveoY/6ZNm0rrZf/tl19+eem6R44cKa3j9FSGPSLW91j8ZAu9AGgRp8sCSRB2IAnCDiRB2IEkCDuQBENcR8Bll11Wa/0lS5b0rVUdOqs69Falagjs1NRU31rV8NhrrrmmtL5z587SelYDD3EFcHYg7EAShB1IgrADSRB2IAnCDiRB2IEkmLJ5BLz//vudrl/HwoULS+tlx9KrjvHXPQcAJ2PLDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJcJwdrSr7vYSqsfZtTlWdEVt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiiMuy2L7X9K9t7bO+2/e1i+WLb222/XVwvar9dnGls971guOazZf9Y0ncj4quS/lLSt2x/VdJ9knZExBWSdhT3AYyoyrBHxKGI2Fnc/kjSXknLJa2RNFk8bFLS2pZ6BNCA0/rMbvuLkr4u6RVJSyPiUFH6QNLSZlsD0KR5nxtv+/OSfiHpOxHxu7mfuSIi+s3jZntc0njdRgHUM68tu+3zNRv0n0bE5mLxYdvLivoySTO91o2IiYgYi4ixJhoGMJj5fBtvSU9K2hsRP5pT2ippQ3F7g6Tnm28PQFPmsxv/V5K+KekN268VyzZKelTSz23fKek9Sbe30iHOaGVDXDdv3ty3huZVhj0iXpbU76DoDc22A6AtnEEHJEHYgSQIO5AEYQeSIOxAEoQdSIKfkkaryoayHj16dIidgC07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBcXa0qmw8e1kNzWPLDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJcJwdrSobzz4xMTHETsCWHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSqAy77Utt/8r2Htu7bX+7WP6g7YO2Xysut7bfLs40EdH3guGaz0k1H0v6bkTstH2BpFdtby9qP46If2qvPQBNqQx7RBySdKi4/ZHtvZKWt90YgGad1md221+U9HVJrxSL7rX9uu2nbC/qs8647Wnb0/VaBVDHvMNu+/OSfiHpOxHxO0k/kfRlSVdrdsv/w17rRcRERIxFxFj9dgEMal5ht32+ZoP+04jYLEkRcTgijkfECUmbJK1sr00Adc3n23hLelLS3oj40Zzly+Y8bJ2kXc23B6AprjoEYvtaSS9JekPSiWLxRknrNbsLH5L2Sbqn+DKv7Lk43gK0LCJ6jiuuDHuTCDvQvn5h5ww6IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEsOesvmIpPfm3F9SLBtFo9rbqPYl0dugmuzt8n6FoY5n/8yL29Oj+tt0o9rbqPYl0dughtUbu/FAEoQdSKLrsE90/PplRrW3Ue1LordBDaW3Tj+zAxierrfsAIaEsANJdBJ226ttv2X7Hdv3ddFDP7b32X6jmIa60/npijn0ZmzvmrNsse3ttt8urnvOsddRbyMxjXfJNOOdvnddT38+9M/sts+V9FtJN0o6IGlK0vqI2DPURvqwvU/SWER0fgKG7esk/V7Sv0TEVcWyf5R0NCIeLf6hXBQRfzcivT0o6fddT+NdzFa0bO4045LWSvobdfjelfR1u4bwvnWxZV8p6Z2IeDci/ijpZ5LWdNDHyIuIFyUdPWXxGkmTxe1Jzf6xDF2f3kZCRByKiJ3F7Y8kfTLNeKfvXUlfQ9FF2JdL2j/n/gGN1nzvIWmb7Vdtj3fdTA9L50yz9YGkpV0200PlNN7DdMo04yPz3g0y/XldfEH3WddGxF9IukXSt4rd1ZEUs5/BRunY6bym8R6WHtOMf6rL927Q6c/r6iLsByVdOuf+F4plIyEiDhbXM5K2aPSmoj78yQy6xfVMx/18apSm8e41zbhG4L3rcvrzLsI+JekK21+y/TlJ35C0tYM+PsP2wuKLE9leKOkmjd5U1FslbShub5D0fIe9nGRUpvHuN824On7vOp/+PCKGfpF0q2a/kf8fSX/fRQ99+vpTSf9dXHZ33ZukZzW7W/d/mv1u405JF0raIeltSb+UtHiEevtXzU7t/bpmg7Wso96u1ewu+uuSXisut3b93pX0NZT3jdNlgST4gg5IgrADSRB2IAnCDiRB2IEkCDuQBGEHkvh/ICBTXDW3nAMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rand: int = int(np.random.randn()*n_test)\n",
    "pt.imshow(x_train[rand].reshape(28, 28), cmap='gray')\n",
    "pt.title(y_train[rand])\n",
    "pt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "better-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_perm = np.random.permutation(n_train)\n",
    "x_train = x_train[rand_perm]\n",
    "y_train = y_train[rand_perm]\n",
    "\n",
    "y_train = tf.one_hot(y_train, depth=10, on_value=1, off_value=0)\n",
    "\n",
    "x_train = x_train[..., np.newaxis]\n",
    "\n",
    "X = x_train[:40000]\n",
    "y = y_train[:40000]\n",
    "\n",
    "x_val = x_train[40000:]\n",
    "y_val = y_train[40000:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-myanmar",
   "metadata": {},
   "source": [
    "### Ok, so most ( really all ) of the data processing is done so lets just get right into the learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-corner",
   "metadata": {},
   "source": [
    "### So up first lets go with a conventional Deep Convolutional Neural Network\n",
    "- Note, we can't go too deep or we will reach the vanishing gradient problem\n",
    "- We can also theoretically do data augmentation, but we will do that later and compare and contrast\n",
    "- We will also start off guns blazing with the normalization and pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-desire",
   "metadata": {},
   "source": [
    "#### Architecture\n",
    "    - Conv Input\n",
    "    - Batch Normalization\n",
    "    - Activation \n",
    "    - Max Pooling\n",
    "---\n",
    "    - Conv Input\n",
    "    - Batch Normalization\n",
    "    - Activation\n",
    "    - Max Pooling\n",
    "---\n",
    "    - Conv Input\n",
    "    - Batch Normalization\n",
    "    - Activation\n",
    "    - Max Pooling\n",
    "---\n",
    "    - Conv Input\n",
    "    - Batch Normalization\n",
    "    - Activation\n",
    "<!--     - Max Pooling -->\n",
    "---\n",
    "    - Conv Input\n",
    "    - Batch Normalization\n",
    "    - Activation\n",
    "    - Average Pooling\n",
    "    - Flatten\n",
    "---\n",
    "    - Dense Layer\n",
    "    - ReLU\n",
    "---\n",
    "    - Dropout \n",
    "    - Dense Layer\n",
    "    - Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cellular-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations as act\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(layers.Conv2D(10, (5, 5), input_shape=(28, 28, 1)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation(act.relu))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(10, (5, 5), padding='same')) # zero padding\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation(act.relu))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(10, (5, 5), padding='same')) # zero padding\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation(act.relu))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(10, (5, 5), padding='same')) # zero padding\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation(act.relu))\n",
    "model.add(layers.AveragePooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(30))\n",
    "model.add(layers.Activation(act.relu))\n",
    "\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(10))\n",
    "model.add(layers.Activation(act.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "angry-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(tf.keras.optimizers.RMSprop(lr=0.0001),\n",
    "                loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy']) \n",
    "# we have an extremely balanced dataset so classification accuracy is valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "peripheral-following",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 24, 24, 10)        260       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 24, 24, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 24, 24, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 12, 12, 10)        2510      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 12, 12, 10)        40        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 6, 10)          2510      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 6, 6, 10)          40        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 10)          2510      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 3, 3, 10)          40        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3, 3, 10)          0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 1, 1, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 30)                330       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 8,590\n",
      "Trainable params: 8,510\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "subjective-honolulu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 4s 7ms/step - loss: 2.1992 - accuracy: 0.1436 - val_loss: 1.8513 - val_accuracy: 0.3668\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.7345 - accuracy: 0.3996 - val_loss: 1.3818 - val_accuracy: 0.6366\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.3671 - accuracy: 0.6098 - val_loss: 0.9974 - val_accuracy: 0.8389\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.0192 - accuracy: 0.7676 - val_loss: 0.6584 - val_accuracy: 0.9250\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.7453 - accuracy: 0.8473 - val_loss: 0.4406 - val_accuracy: 0.9463\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.5537 - accuracy: 0.8805 - val_loss: 0.2954 - val_accuracy: 0.9556\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.4228 - accuracy: 0.9050 - val_loss: 0.2177 - val_accuracy: 0.9603\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3344 - accuracy: 0.9241 - val_loss: 0.1730 - val_accuracy: 0.9635\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2834 - accuracy: 0.9313 - val_loss: 0.1449 - val_accuracy: 0.9666\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2366 - accuracy: 0.9449 - val_loss: 0.1256 - val_accuracy: 0.9682\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2028 - accuracy: 0.9511 - val_loss: 0.1140 - val_accuracy: 0.9694\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1796 - accuracy: 0.9528 - val_loss: 0.1068 - val_accuracy: 0.9712\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1662 - accuracy: 0.9579 - val_loss: 0.0954 - val_accuracy: 0.9740\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1506 - accuracy: 0.9602 - val_loss: 0.0914 - val_accuracy: 0.9743\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1350 - accuracy: 0.9652 - val_loss: 0.0865 - val_accuracy: 0.9749\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1314 - accuracy: 0.9664 - val_loss: 0.0839 - val_accuracy: 0.9755\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1215 - accuracy: 0.9682 - val_loss: 0.0832 - val_accuracy: 0.9758\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1177 - accuracy: 0.9689 - val_loss: 0.0792 - val_accuracy: 0.9769\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.1069 - accuracy: 0.9715 - val_loss: 0.0756 - val_accuracy: 0.9779\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1014 - accuracy: 0.9742 - val_loss: 0.0741 - val_accuracy: 0.9778\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0975 - accuracy: 0.9735 - val_loss: 0.0716 - val_accuracy: 0.9786\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0947 - accuracy: 0.9750 - val_loss: 0.0737 - val_accuracy: 0.9771\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0901 - accuracy: 0.9757 - val_loss: 0.0710 - val_accuracy: 0.9787\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0860 - accuracy: 0.9767 - val_loss: 0.0687 - val_accuracy: 0.9798\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0833 - accuracy: 0.9764 - val_loss: 0.0688 - val_accuracy: 0.9797\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0788 - accuracy: 0.9795 - val_loss: 0.0673 - val_accuracy: 0.9801\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0758 - accuracy: 0.9790 - val_loss: 0.0700 - val_accuracy: 0.9796\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0750 - accuracy: 0.9800 - val_loss: 0.0675 - val_accuracy: 0.9811\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0683 - accuracy: 0.9815 - val_loss: 0.0691 - val_accuracy: 0.9802\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0668 - accuracy: 0.9816 - val_loss: 0.0661 - val_accuracy: 0.9808\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0648 - accuracy: 0.9837 - val_loss: 0.0639 - val_accuracy: 0.9819\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0619 - accuracy: 0.9834 - val_loss: 0.0637 - val_accuracy: 0.9814\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0611 - accuracy: 0.9835 - val_loss: 0.0680 - val_accuracy: 0.9808\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0622 - accuracy: 0.9834 - val_loss: 0.0647 - val_accuracy: 0.9813\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0556 - accuracy: 0.9854 - val_loss: 0.0646 - val_accuracy: 0.9814\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0537 - accuracy: 0.9850 - val_loss: 0.0630 - val_accuracy: 0.9809\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0556 - accuracy: 0.9850 - val_loss: 0.0627 - val_accuracy: 0.9822\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0497 - accuracy: 0.9862 - val_loss: 0.0625 - val_accuracy: 0.9825\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0535 - accuracy: 0.9841 - val_loss: 0.0616 - val_accuracy: 0.9834\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0478 - accuracy: 0.9868 - val_loss: 0.0617 - val_accuracy: 0.9825\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0488 - accuracy: 0.9859 - val_loss: 0.0617 - val_accuracy: 0.9821\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0457 - accuracy: 0.9872 - val_loss: 0.0593 - val_accuracy: 0.9834\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0463 - accuracy: 0.9874 - val_loss: 0.0609 - val_accuracy: 0.9836\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0436 - accuracy: 0.9870 - val_loss: 0.0630 - val_accuracy: 0.9832\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0438 - accuracy: 0.9877 - val_loss: 0.0631 - val_accuracy: 0.9827\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0420 - accuracy: 0.9876 - val_loss: 0.0628 - val_accuracy: 0.9831\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0424 - accuracy: 0.9890 - val_loss: 0.0619 - val_accuracy: 0.9833\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0416 - accuracy: 0.9884 - val_loss: 0.0639 - val_accuracy: 0.9835\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0393 - accuracy: 0.9880 - val_loss: 0.0628 - val_accuracy: 0.9832\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0406 - accuracy: 0.9880 - val_loss: 0.0626 - val_accuracy: 0.9832\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, \n",
    "         batch_size=128,\n",
    "         epochs=50,\n",
    "         validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "technological-brick",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-749b5e25c88d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training Accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Validation Accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_acc'"
     ]
    }
   ],
   "source": [
    "epochs = range(50)\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_acc']\n",
    "pt.plot(epochs, train_acc, 'bo', label=\"Training Accuracy\")\n",
    "pt.plot(epochs, val_acc, 'r', label=\"Validation Accuracy\")\n",
    "pt.xlabel(\"Epochs\")\n",
    "pt.ylabel=(\"Accuracy\")\n",
    "pt.legend()\n",
    "pt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs583",
   "language": "python",
   "name": "cs583"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
